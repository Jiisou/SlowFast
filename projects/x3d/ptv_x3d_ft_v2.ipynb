{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c0d7fcea",
      "metadata": {
        "id": "c0d7fcea"
      },
      "source": [
        "# Finetune the X3D\n",
        "\n",
        "* Original Author: FAIR PyTorchVideo*\n",
        "\n",
        "> I start with X3D network pretrained on the Kinetics 400 dataset and finetune it on the UCF-CRIME dataset for video anomaly detection.\n",
        "\n",
        "\n",
        "#### install dependencies\n",
        "\n",
        "```\n",
        "!pip install 'git+https://github.com/facebookresearch/fvcore'\n",
        "\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg libsm6 libxext6\n",
        "\n",
        "!pip install av or conda install av -c conda-forge -y\n",
        "!pip install opencv-python pandas\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DDM2cVoLr4O_",
      "metadata": {
        "id": "DDM2cVoLr4O_"
      },
      "source": [
        "\n",
        "#### Imports\n",
        "\n",
        "Load the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c84b32ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c84b32ed",
        "outputId": "5ed9118e-f75e-4097-ec78-3b1a8c756b8a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/etri/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# Choose the `x3d_s` model to load\n",
        "model_name = 'x3d_m'\n",
        "model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "GESdR1i4oMSV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GESdR1i4oMSV",
        "outputId": "8326c5b6-767a-4a52-ab7e-d38432f410e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (blocks): ModuleList(\n",
              "    (0): ResNetBasicStem(\n",
              "      (conv): Conv2plus1d(\n",
              "        (conv_t): Conv3d(3, 24, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "        (conv_xy): Conv3d(24, 24, kernel_size=(5, 1, 1), stride=(1, 1, 1), padding=(2, 0, 0), groups=24, bias=False)\n",
              "      )\n",
              "      (norm): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU()\n",
              "    )\n",
              "    (1): ResStage(\n",
              "      (res_blocks): ModuleList(\n",
              "        (0): ResBlock(\n",
              "          (branch1_conv): Conv3d(24, 24, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(24, 54, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(54, 54, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=54, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(54, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(8, 54, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(54, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (1): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(24, 54, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(54, 54, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=54, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): Identity()\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(54, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (2): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(24, 54, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(54, 54, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=54, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(54, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(8, 54, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(54, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): ResStage(\n",
              "      (res_blocks): ModuleList(\n",
              "        (0): ResBlock(\n",
              "          (branch1_conv): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "          (branch1_norm): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(24, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=108, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(108, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(8, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(108, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (1): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(48, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=108, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): Identity()\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(108, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (2): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(48, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=108, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(108, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(8, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(108, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (3): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(48, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=108, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): Identity()\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(108, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (4): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(48, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=108, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(108, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(8, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(108, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): ResStage(\n",
              "      (res_blocks): ModuleList(\n",
              "        (0): ResBlock(\n",
              "          (branch1_conv): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "          (branch1_norm): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(48, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=216, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(216, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(16, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (1): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): Identity()\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (2): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(216, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(16, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (3): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): Identity()\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (4): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(216, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(16, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (5): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): Identity()\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (6): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(216, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(16, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (7): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): Identity()\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (8): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(216, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(16, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (9): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): Identity()\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (10): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(216, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(16, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): ResStage(\n",
              "      (res_blocks): ModuleList(\n",
              "        (0): ResBlock(\n",
              "          (branch1_conv): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "          (branch1_norm): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(96, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=432, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(432, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(32, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (1): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=432, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): Identity()\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (2): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=432, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(432, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(32, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (3): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=432, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): Identity()\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (4): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=432, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(432, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(32, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (5): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=432, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): Identity()\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (6): ResBlock(\n",
              "          (branch2): BottleneckBlock(\n",
              "            (conv_a): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_a): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act_a): ReLU()\n",
              "            (conv_b): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=432, bias=False)\n",
              "            (norm_b): Sequential(\n",
              "              (0): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (1): SqueezeExcitation(\n",
              "                (block): Sequential(\n",
              "                  (0): Conv3d(432, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (1): ReLU()\n",
              "                  (2): Conv3d(32, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "                  (3): Sigmoid()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (act_b): Swish()\n",
              "            (conv_c): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "            (norm_c): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): ResNetBasicHead(\n",
              "      (pool): ProjectedPool(\n",
              "        (pre_conv): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (pre_norm): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (pre_act): ReLU()\n",
              "        (pool): AvgPool3d(kernel_size=(np.int64(16), 7, 7), stride=1, padding=0)\n",
              "        (post_conv): Conv3d(432, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (post_act): ReLU()\n",
              "      )\n",
              "      (dropout): Dropout(p=0.5, inplace=False)\n",
              "      (proj): Linear(in_features=2048, out_features=400, bias=True)\n",
              "      (output_pool): AdaptiveAvgPool3d(output_size=1)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JC-07DnIKKjx",
      "metadata": {
        "id": "JC-07DnIKKjx"
      },
      "source": [
        "#### Original Classes for UCF-CRIME (Abnormal 13 + Normal 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "HTZ1MjBTqmpz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTZ1MjBTqmpz",
        "outputId": "10abd894-0de6-4f3f-cd9b-76d86df4f9a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ResNetBasicHead(\n",
              "  (pool): ProjectedPool(\n",
              "    (pre_conv): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "    (pre_norm): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (pre_act): ReLU()\n",
              "    (pool): AvgPool3d(kernel_size=(np.int64(16), 7, 7), stride=1, padding=0)\n",
              "    (post_conv): Conv3d(432, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "    (post_act): ReLU()\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (proj): Linear(in_features=2048, out_features=400, bias=True)\n",
              "  (output_pool): AdaptiveAvgPool3d(output_size=1)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(model.blocks[5]==model.blocks[-1])\n",
        "model.blocks[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "Y5V__qqCJve9",
      "metadata": {
        "id": "Y5V__qqCJve9"
      },
      "outputs": [],
      "source": [
        "num_classes = 14 # UCF-CRIME 클래스 개수\n",
        "\n",
        "in_features = model.blocks[5].proj.in_features # 기존 레이어의 입력 피처 크기 추출\n",
        "\n",
        "# model.blocks[5].proj = torch.nn.Linear(model.blocks[5].proj.in_features, num_classes)\n",
        "model.blocks[5].proj = torch.nn.Linear(in_features, num_classes) # Final Linear 레이어만 교체 (*가장 쉬운 가중치 보존 방법)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "nsKKn2T8nGS9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsKKn2T8nGS9",
        "outputId": "3b3cb5cb-ac79-40fa-dc7e-614b36a23b66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2048"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "in_features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PBgWCL7Dth-n",
      "metadata": {
        "id": "PBgWCL7Dth-n"
      },
      "source": [
        "> $y = W x + b$\n",
        "\n",
        "- $x \\in \\mathbb{R}^{2048}$ : 풀링을 가친 특징 벡터 (여기선 2048 차원)\n",
        "\n",
        "- $W \\in \\mathbb{R}^{N \\times 2048}$ : 학습시켜야할 새 가중치 행렬"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5151878c",
      "metadata": {
        "id": "5151878c"
      },
      "source": [
        "Import remaining functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5fc0302d",
      "metadata": {
        "id": "5fc0302d"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import urllib\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo\n",
        "\n",
        "from torchvision.transforms import Compose, Lambda\n",
        "from torchvision.transforms._transforms_video import (\n",
        "    CenterCropVideo,\n",
        "    NormalizeVideo,\n",
        ")\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    ShortSideScale,\n",
        "    UniformTemporalSubsample\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8593c1f6",
      "metadata": {
        "id": "8593c1f6"
      },
      "source": [
        "#### Setup\n",
        "\n",
        "Set the model to eval mode and move to desired device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "DXypxC_NsEpP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXypxC_NsEpP",
        "outputId": "af67c84d-bf70-473e-c471-f145c50262ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a38cb73f",
      "metadata": {
        "id": "a38cb73f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected Device is cuda\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Set to GPU or CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Selected Device is {device}\\n\")\n",
        "model = model.eval()\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c28831bd",
      "metadata": {
        "id": "c28831bd"
      },
      "source": [
        "#### Define input transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e2CgnpXK9vOu",
      "metadata": {
        "id": "e2CgnpXK9vOu"
      },
      "outputs": [],
      "source": [
        "mean = [0.45, 0.45, 0.45]\n",
        "std = [0.225, 0.225, 0.225]\n",
        "frames_per_second = 30\n",
        "model_transform_params  = {\n",
        "    \"x3d_xs\": {\n",
        "        \"side_size\": 182,\n",
        "        \"crop_size\": 182,\n",
        "        \"num_frames\": 4,\n",
        "        \"sampling_rate\": 12,\n",
        "    },\n",
        "    \"x3d_s\": {\n",
        "        \"side_size\": 182,\n",
        "        \"crop_size\": 182,\n",
        "        \"num_frames\": 13,\n",
        "        \"sampling_rate\": 6,\n",
        "    },\n",
        "    \"x3d_m\": {\n",
        "        \"side_size\": 256,\n",
        "        \"train_crop_size\": 224,\n",
        "        \"test_crop_size\": 256,\n",
        "        \"num_frames\": 16,\n",
        "        \"sampling_rate\": 5,\n",
        "    },\n",
        "    \"x3d_l\": {\n",
        "        \"side_size\": 356,\n",
        "        \"train_crop_size\": 312,\n",
        "        \"test_crop_size\": 356,\n",
        "        \"num_frames\": 16,\n",
        "        \"sampling_rate\": 5,\n",
        "    }\n",
        "}\n",
        "\n",
        "# Get transform parameters based on model\n",
        "transform_params = model_transform_params[model_name]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe8cc917",
      "metadata": {},
      "source": [
        "#### Kinetic Dataset Label(.json) and a sample video"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "424b24da",
      "metadata": {
        "id": "424b24da"
      },
      "source": [
        "Download the id to label mapping for the Kinetics 400 dataset on which the torch hub models were trained. This will be used to get the category label names from the predicted class ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "563dc260",
      "metadata": {
        "id": "563dc260"
      },
      "outputs": [],
      "source": [
        "json_url = \"https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json\"\n",
        "json_filename = \"kinetics_classnames.json\"\n",
        "try: urllib.URLopener().retrieve(json_url, json_filename)\n",
        "except: urllib.request.urlretrieve(json_url, json_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e9961f72",
      "metadata": {
        "id": "e9961f72"
      },
      "outputs": [],
      "source": [
        "with open(json_filename, \"r\") as f:\n",
        "    kinetics_classnames = json.load(f)\n",
        "\n",
        "# Create an id to label name mapping\n",
        "kinetics_id_to_classname = {}\n",
        "for k, v in kinetics_classnames.items():\n",
        "    kinetics_id_to_classname[v] = str(k).replace('\"', \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "IprwDrtD3jPJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IprwDrtD3jPJ",
        "outputId": "3b67f2e2-22cd-4b78-d3ae-3974992ff5cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{290: 'sharpening knives',\n",
              " 115: 'eating ice cream',\n",
              " 81: 'cutting nails',\n",
              " 53: 'changing wheel',\n",
              " 19: 'bench pressing',\n",
              " 88: 'deadlifting',\n",
              " 111: 'eating carrots',\n",
              " 192: 'marching',\n",
              " 358: 'throwing discus',\n",
              " 231: 'playing flute',\n",
              " 72: 'cooking on campfire',\n",
              " 33: 'breading or breadcrumbing',\n",
              " 218: 'playing badminton',\n",
              " 276: 'ripping paper',\n",
              " 244: 'playing saxophone',\n",
              " 197: 'milking cow',\n",
              " 169: 'juggling balls',\n",
              " 130: 'flying kite',\n",
              " 43: 'capoeira',\n",
              " 187: 'making jewelry',\n",
              " 100: 'drinking',\n",
              " 228: 'playing cymbals',\n",
              " 61: 'cleaning gutters',\n",
              " 161: 'hurling (sport)',\n",
              " 239: 'playing organ',\n",
              " 361: 'tossing coin',\n",
              " 395: 'wrestling',\n",
              " 103: 'driving car',\n",
              " 150: 'headbutting',\n",
              " 147: 'gymnastics tumbling',\n",
              " 186: 'making bed',\n",
              " 0: 'abseiling',\n",
              " 155: 'holding snake',\n",
              " 278: 'rock climbing',\n",
              " 71: 'cooking egg',\n",
              " 182: 'long jump',\n",
              " 17: 'bee keeping',\n",
              " 365: 'trimming or shaving beard',\n",
              " 63: 'cleaning shoes',\n",
              " 86: 'dancing gangnam style',\n",
              " 50: 'catching or throwing softball',\n",
              " 164: 'ice skating',\n",
              " 168: 'jogging',\n",
              " 116: 'eating spaghetti',\n",
              " 28: 'bobsledding',\n",
              " 8: 'assembling computer',\n",
              " 227: 'playing cricket',\n",
              " 238: 'playing monopoly',\n",
              " 143: 'golf putting',\n",
              " 188: 'making pizza',\n",
              " 166: 'javelin throw',\n",
              " 211: 'peeling potatoes',\n",
              " 57: 'clapping',\n",
              " 36: 'brushing hair',\n",
              " 129: 'flipping pancake',\n",
              " 101: 'drinking beer',\n",
              " 99: 'dribbling basketball',\n",
              " 219: 'playing bagpipes',\n",
              " 325: 'somersaulting',\n",
              " 42: 'canoeing or kayaking',\n",
              " 275: 'riding unicycle',\n",
              " 355: 'texting',\n",
              " 352: 'tasting beer',\n",
              " 154: 'hockey stop',\n",
              " 225: 'playing clarinet',\n",
              " 389: 'waxing legs',\n",
              " 80: 'curling hair',\n",
              " 281: 'running on treadmill',\n",
              " 346: 'tai chi',\n",
              " 104: 'driving tractor',\n",
              " 293: 'shaving legs',\n",
              " 291: 'sharpening pencil',\n",
              " 190: 'making sushi',\n",
              " 327: 'spray painting',\n",
              " 305: 'situp',\n",
              " 237: 'playing kickball',\n",
              " 331: 'sticking tongue out',\n",
              " 149: 'headbanging',\n",
              " 132: 'folding napkins',\n",
              " 241: 'playing piano',\n",
              " 312: 'skydiving',\n",
              " 85: 'dancing charleston',\n",
              " 163: 'ice fishing',\n",
              " 359: 'tickling',\n",
              " 13: 'bandaging',\n",
              " 151: 'high jump',\n",
              " 185: 'making a sandwich',\n",
              " 271: 'riding mountain bike',\n",
              " 82: 'cutting pineapple',\n",
              " 125: 'feeding goats',\n",
              " 87: 'dancing macarena',\n",
              " 220: 'playing basketball',\n",
              " 179: 'krumping',\n",
              " 152: 'high kick',\n",
              " 12: 'balloon blowing',\n",
              " 217: 'playing accordion',\n",
              " 224: 'playing chess',\n",
              " 159: 'hula hooping',\n",
              " 263: 'pushing wheelchair',\n",
              " 268: 'riding camel',\n",
              " 27: 'blowing out candles',\n",
              " 121: 'extinguishing fire',\n",
              " 373: 'using computer',\n",
              " 173: 'jumpstyle dancing',\n",
              " 397: 'yawning',\n",
              " 396: 'writing',\n",
              " 172: 'jumping into pool',\n",
              " 96: 'doing laundry',\n",
              " 118: 'egg hunting',\n",
              " 284: 'sanding floor',\n",
              " 200: 'moving furniture',\n",
              " 119: 'exercising arm',\n",
              " 345: 'sword fighting',\n",
              " 303: 'sign language interpreting',\n",
              " 74: 'counting money',\n",
              " 15: 'bartending',\n",
              " 65: 'cleaning windows',\n",
              " 23: 'blasting sand',\n",
              " 213: 'petting cat',\n",
              " 320: 'sniffing',\n",
              " 31: 'bowling',\n",
              " 242: 'playing poker',\n",
              " 347: 'taking a shower',\n",
              " 382: 'washing hands',\n",
              " 384: 'water sliding',\n",
              " 254: 'presenting weather forecast',\n",
              " 360: 'tobogganing',\n",
              " 51: 'celebrating',\n",
              " 138: 'getting a haircut',\n",
              " 321: 'snorkeling',\n",
              " 390: 'weaving basket',\n",
              " 245: 'playing squash or racquetball',\n",
              " 206: 'parasailing',\n",
              " 202: 'news anchoring',\n",
              " 18: 'belly dancing',\n",
              " 393: 'windsurfing',\n",
              " 32: 'braiding hair',\n",
              " 78: 'crossing river',\n",
              " 181: 'laying bricks',\n",
              " 280: 'roller skating',\n",
              " 156: 'hopscotch',\n",
              " 248: 'playing trumpet',\n",
              " 108: 'dying hair',\n",
              " 366: 'trimming trees',\n",
              " 256: 'pumping fist',\n",
              " 236: 'playing keyboard',\n",
              " 322: 'snowboarding',\n",
              " 136: 'garbage collecting',\n",
              " 226: 'playing controller',\n",
              " 94: 'dodgeball',\n",
              " 266: 'recording music',\n",
              " 75: 'country line dancing',\n",
              " 84: 'dancing ballet',\n",
              " 137: 'gargling',\n",
              " 165: 'ironing',\n",
              " 260: 'push up',\n",
              " 135: 'frying vegetables',\n",
              " 307: 'ski jumping',\n",
              " 201: 'mowing lawn',\n",
              " 139: 'getting a tattoo',\n",
              " 279: 'rock scissors paper',\n",
              " 55: 'cheerleading',\n",
              " 374: 'using remote controller (not gaming)',\n",
              " 289: 'shaking head',\n",
              " 282: 'sailing',\n",
              " 363: 'training dog',\n",
              " 160: 'hurdling',\n",
              " 128: 'fixing hair',\n",
              " 67: 'climbing ladder',\n",
              " 126: 'filling eyebrows',\n",
              " 329: 'springboard diving',\n",
              " 117: 'eating watermelon',\n",
              " 106: 'drumming fingers',\n",
              " 386: 'waxing back',\n",
              " 229: 'playing didgeridoo',\n",
              " 339: 'swimming backstroke',\n",
              " 22: 'biking through snow',\n",
              " 380: 'washing feet',\n",
              " 198: 'mopping floor',\n",
              " 357: 'throwing ball',\n",
              " 113: 'eating doughnuts',\n",
              " 102: 'drinking shots',\n",
              " 368: 'tying bow tie',\n",
              " 91: 'dining',\n",
              " 337: 'surfing water',\n",
              " 338: 'sweeping floor',\n",
              " 145: 'grooming dog',\n",
              " 47: 'catching fish',\n",
              " 257: 'pumping gas',\n",
              " 273: 'riding or walking with horse',\n",
              " 196: \"massaging person's head\",\n",
              " 5: 'archery',\n",
              " 162: 'ice climbing',\n",
              " 243: 'playing recorder',\n",
              " 89: 'decorating the christmas tree',\n",
              " 210: 'peeling apples',\n",
              " 324: 'snowmobiling',\n",
              " 249: 'playing ukulele',\n",
              " 109: 'eating burger',\n",
              " 38: 'building cabinet',\n",
              " 332: 'stomping grapes',\n",
              " 105: 'drop kicking',\n",
              " 209: 'passing American football (not in game)',\n",
              " 3: 'applauding',\n",
              " 158: 'hugging',\n",
              " 114: 'eating hotdog',\n",
              " 253: 'pole vault',\n",
              " 265: 'reading newspaper',\n",
              " 318: 'snatch weight lifting',\n",
              " 399: 'zumba',\n",
              " 235: 'playing ice hockey',\n",
              " 34: 'breakdancing',\n",
              " 124: 'feeding fish',\n",
              " 300: 'shredding paper',\n",
              " 49: 'catching or throwing frisbee',\n",
              " 120: 'exercising with an exercise ball',\n",
              " 262: 'pushing cart',\n",
              " 341: 'swimming butterfly stroke',\n",
              " 274: 'riding scooter',\n",
              " 328: 'spraying',\n",
              " 133: 'folding paper',\n",
              " 142: 'golf driving',\n",
              " 277: 'robot dancing',\n",
              " 20: 'bending back',\n",
              " 354: 'testifying',\n",
              " 387: 'waxing chest',\n",
              " 46: 'carving pumpkin',\n",
              " 153: 'hitting baseball',\n",
              " 269: 'riding elephant',\n",
              " 37: 'brushing teeth',\n",
              " 255: 'pull ups',\n",
              " 267: 'riding a bike',\n",
              " 306: 'skateboarding',\n",
              " 62: 'cleaning pool',\n",
              " 240: 'playing paintball',\n",
              " 193: 'massaging back',\n",
              " 299: 'shoveling snow',\n",
              " 336: 'surfing crowd',\n",
              " 371: 'unboxing',\n",
              " 122: 'faceplanting',\n",
              " 364: 'trapezing',\n",
              " 343: 'swinging legs',\n",
              " 157: 'hoverboarding',\n",
              " 250: 'playing violin',\n",
              " 394: 'wrapping present',\n",
              " 26: 'blowing nose',\n",
              " 174: 'kicking field goal',\n",
              " 214: 'picking fruit',\n",
              " 344: 'swinging on something',\n",
              " 140: 'giving or receiving award',\n",
              " 215: 'planting trees',\n",
              " 383: 'water skiing',\n",
              " 379: 'washing dishes',\n",
              " 258: 'punching bag',\n",
              " 195: 'massaging legs',\n",
              " 356: 'throwing axe',\n",
              " 283: 'salsa dancing',\n",
              " 29: 'bookbinding',\n",
              " 370: 'tying tie',\n",
              " 309: 'skiing crosscountry',\n",
              " 295: 'shining shoes',\n",
              " 189: 'making snowman',\n",
              " 134: 'front raises',\n",
              " 97: 'doing nails',\n",
              " 194: 'massaging feet',\n",
              " 230: 'playing drums',\n",
              " 316: 'smoking',\n",
              " 259: 'punching person (boxing)',\n",
              " 45: 'cartwheeling',\n",
              " 208: 'passing American football (in game)',\n",
              " 288: 'shaking hands',\n",
              " 216: 'plastering',\n",
              " 385: 'watering plants',\n",
              " 176: 'kissing',\n",
              " 314: 'slapping',\n",
              " 233: 'playing harmonica',\n",
              " 391: 'welding',\n",
              " 317: 'smoking hookah',\n",
              " 285: 'scrambling eggs',\n",
              " 70: 'cooking chicken',\n",
              " 261: 'pushing car',\n",
              " 203: 'opening bottle',\n",
              " 73: 'cooking sausages',\n",
              " 48: 'catching or throwing baseball',\n",
              " 340: 'swimming breast stroke',\n",
              " 90: 'digging',\n",
              " 252: 'playing xylophone',\n",
              " 95: 'doing aerobics',\n",
              " 247: 'playing trombone',\n",
              " 178: 'knitting',\n",
              " 377: 'waiting in line',\n",
              " 362: 'tossing salad',\n",
              " 330: 'squat',\n",
              " 376: 'vault',\n",
              " 375: 'using segway',\n",
              " 77: 'crawling baby',\n",
              " 264: 'reading book',\n",
              " 199: 'motorcycling',\n",
              " 14: 'barbequing',\n",
              " 60: 'cleaning floor',\n",
              " 223: 'playing cello',\n",
              " 98: 'drawing',\n",
              " 9: 'auctioning',\n",
              " 44: 'carrying baby',\n",
              " 93: 'diving cliff',\n",
              " 41: 'busking',\n",
              " 83: 'cutting watermelon',\n",
              " 286: 'scuba diving',\n",
              " 270: 'riding mechanical bull',\n",
              " 191: 'making tea',\n",
              " 246: 'playing tennis',\n",
              " 79: 'crying',\n",
              " 107: 'dunking basketball',\n",
              " 76: 'cracking neck',\n",
              " 7: 'arranging flowers',\n",
              " 39: 'building shed',\n",
              " 141: 'golf chipping',\n",
              " 353: 'tasting food',\n",
              " 292: 'shaving head',\n",
              " 2: 'answering questions',\n",
              " 68: 'climbing tree',\n",
              " 311: 'skipping rope',\n",
              " 177: 'kitesurfing',\n",
              " 170: 'juggling fire',\n",
              " 180: 'laughing',\n",
              " 205: 'paragliding',\n",
              " 69: 'contact juggling',\n",
              " 313: 'slacklining',\n",
              " 6: 'arm wrestling',\n",
              " 184: 'making a cake',\n",
              " 127: 'finger snapping',\n",
              " 146: 'grooming horse',\n",
              " 204: 'opening present',\n",
              " 351: 'tapping pen',\n",
              " 304: 'singing',\n",
              " 298: 'shot put',\n",
              " 64: 'cleaning toilet',\n",
              " 326: 'spinning poi',\n",
              " 287: 'setting table',\n",
              " 369: 'tying knot (not on a tie)',\n",
              " 24: 'blowing glass',\n",
              " 112: 'eating chips',\n",
              " 349: 'tap dancing',\n",
              " 66: 'climbing a rope',\n",
              " 35: 'brush painting',\n",
              " 56: 'chopping wood',\n",
              " 334: 'stretching leg',\n",
              " 212: 'petting animal (not cat)',\n",
              " 11: 'baking cookies',\n",
              " 333: 'stretching arm',\n",
              " 16: 'beatboxing',\n",
              " 167: 'jetskiing',\n",
              " 21: 'bending metal',\n",
              " 319: 'sneezing',\n",
              " 131: 'folding clothes',\n",
              " 315: 'sled dog racing',\n",
              " 350: 'tapping guitar',\n",
              " 30: 'bouncing on trampoline',\n",
              " 388: 'waxing eyebrows',\n",
              " 1: 'air drumming',\n",
              " 175: 'kicking soccer ball',\n",
              " 381: 'washing hair',\n",
              " 272: 'riding mule',\n",
              " 25: 'blowing leaves',\n",
              " 335: 'strumming guitar',\n",
              " 222: 'playing cards',\n",
              " 323: 'snowkiting',\n",
              " 221: 'playing bass guitar',\n",
              " 4: 'applying cream',\n",
              " 296: 'shooting basketball',\n",
              " 378: 'walking the dog',\n",
              " 367: 'triple jump',\n",
              " 294: 'shearing sheep',\n",
              " 58: 'clay pottery making',\n",
              " 40: 'bungee jumping',\n",
              " 372: 'unloading truck',\n",
              " 301: 'shuffling cards',\n",
              " 297: 'shooting goal (soccer)',\n",
              " 348: 'tango dancing',\n",
              " 302: 'side kick',\n",
              " 144: 'grinding meat',\n",
              " 398: 'yoga',\n",
              " 148: 'hammer throw',\n",
              " 52: 'changing oil',\n",
              " 54: 'checking tires',\n",
              " 207: 'parkour',\n",
              " 110: 'eating cake',\n",
              " 310: 'skiing slalom',\n",
              " 171: 'juggling soccer ball',\n",
              " 392: 'whistling',\n",
              " 123: 'feeding birds',\n",
              " 251: 'playing volleyball',\n",
              " 342: 'swing dancing',\n",
              " 308: 'skiing (not slalom or crosscountry)',\n",
              " 183: 'lunge',\n",
              " 92: 'disc golfing',\n",
              " 59: 'clean and jerk',\n",
              " 232: 'playing guitar',\n",
              " 10: 'baby waking up',\n",
              " 234: 'playing harp'}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kinetics_id_to_classname"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D7HqW7r6CqnY",
      "metadata": {
        "id": "D7HqW7r6CqnY"
      },
      "source": [
        "#### **UCF-Crime Data Formatting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ded6169b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resolution of trimmed videos is 320.0 x 240.0\n",
            "FPS of trimmed videos is 3.0\n"
          ]
        }
      ],
      "source": [
        "# Simply inspect the dataset\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# wsl 경로에 유의\n",
        "vid_sample_path = r\"/mnt/c/KJM/abnormal_behavior/DB/UCF_Crimes/Videos/train/Arson/Arson002_x264.mp4\"\n",
        "trimmed_sample_path = r\"/mnt/c/KJM/abnormal_behavior/DB/UCF_Crimes/Action_Regnition_splits(classifiction)/test_001_trimmed_3fps_16sec/Abuse/Abuse001_x264_trimmed.mp4\"\n",
        "\n",
        "vid_sample_path = trimmed_sample_path\n",
        "cap = cv2.VideoCapture(vid_sample_path)\n",
        "if not os.path.exists(vid_sample_path):\n",
        "    print(\"경로에 파일이 없습니다. 경로를 다시 확인하세요.\")\n",
        "else: \n",
        "    print(f\"Resolution of trimmed videos is {cap.get(cv2.CAP_PROP_FRAME_WIDTH)} x {cap.get(cv2.CAP_PROP_FRAME_HEIGHT)}\")\n",
        "    print(f\"FPS of trimmed videos is {cap.get(cv2.CAP_PROP_FPS)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "g36_N6cUDmK0",
      "metadata": {
        "id": "g36_N6cUDmK0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculated clip duration is 2.6666666666666665\n"
          ]
        }
      ],
      "source": [
        "# 비디오 전처리: X3D 모델 입력 전, 데이터를 일정한 규격으로 맞추기 위한 전처리\n",
        "transform =  ApplyTransformToKey( # pytorchvideo.transforms.ApplyTransformToKey\n",
        "    key=\"video\",\n",
        "    transform=Compose(\n",
        "        [\n",
        "            UniformTemporalSubsample(transform_params[\"num_frames\"]),  # 균등한 간격으로 추출할 프레임 개수\n",
        "            Lambda(lambda x: x/255.0), # 0~255 범위의 픽셀값을 0~1로 정규화\n",
        "            NormalizeVideo(mean, std), # Kinetics로 사전학습한 픽셀 값 평균과 표준편차로 채널 정규화\n",
        "            ShortSideScale(size=transform_params[\"side_size\"]), # 가로/세로 중 짧은 변 기준 크롭\n",
        "            CenterCropVideo(                                    # 앞서 크롭된 프레임 중앙에서 정방향 크롭\n",
        "                crop_size=(transform_params[\"train_crop_size\"], transform_params[\"train_crop_size\"])\n",
        "            )\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "# The duration of the input clip is also specific to the model.\n",
        "clip_duration = (transform_params[\"num_frames\"] * transform_params[\"sampling_rate\"])/frames_per_second\n",
        "\n",
        "print(f\"Calculated clip duration is {clip_duration}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "H3NMcpNgEDaU",
      "metadata": {
        "id": "H3NMcpNgEDaU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo # ptv의 EncodedVideo 클래스를 활용하면 비디오 전체를 읽지 않고도 특정 시간대 효율적으로 로드 가능 \n",
        "\n",
        "def time_to_seconds(time_str):\n",
        "    \"\"\"\n",
        "    '0:00:06' 또는 '00:06' 형태의 문자열을 초(float) 단위로 변환.\n",
        "    \"\"\"\n",
        "    if pd.isna(time_str) or time_str == \"\":\n",
        "        return 0.0\n",
        "        \n",
        "    # 숫자와 콜론(:)만 추출 (뒤에 붙는 문자열 무시)\n",
        "    time_match = re.search(r\"(\\d+:?\\d*:?\\d*)\", str(time_str))\n",
        "    if not time_match:\n",
        "        return 0.0\n",
        "    \n",
        "    clean_time_str = time_match.group(1)\n",
        "    parts = str(clean_time_str).split(':')\n",
        "    # HH:MM:SS 형식\n",
        "    if len(parts) == 3:\n",
        "        return float(parts[0]) * 3600 + float(parts[1]) * 60 + float(parts[2])\n",
        "    # MM:SS 형식\n",
        "    elif len(parts) == 2:\n",
        "        return float(parts[0]) * 60 + float(parts[1])\n",
        "    # 이미 숫자 형태인 경우\n",
        "    try:\n",
        "        return float(time_str)\n",
        "    except ValueError:\n",
        "        return 0.0\n",
        "\n",
        "class UCFCrimeDataset(Dataset):\n",
        "    def __init__(self, root_dir, annotation_dir, transform=None):\n",
        "        \"\"\"\n",
        "        root_dir: 'train/' 폴더 경로\n",
        "        annotation_dir: 'train/00_timestamp/' 폴더 경로\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.clip_metadata = []\n",
        "\n",
        "        # CSV 파일들을 읽어 (파일 경로, 시작 시간, 종료 시간, 클래스 인덱스) 리스트 생성\n",
        "        classes = sorted([d for d in os.listdir(root_dir) \n",
        "                        if os.path.isdir(os.path.join(root_dir, d)) and d != '00_timestamp'])\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
        "\n",
        "        for cls in classes:\n",
        "            csv_path = os.path.join(annotation_dir, f\"{cls}_timestamps.csv\")\n",
        "            if not os.path.exists(csv_path):\n",
        "                print(f\"\\nCSV file not found: {csv_path}\")\n",
        "                continue\n",
        "            \n",
        "            try: \n",
        "                df = pd.read_csv(csv_path, on_bad_lines='skip', engine='c') # 오타등으로 CSV 파일에서 잘못된 줄이 있다면 건너뛰고 읽음\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not read {csv_path}. Error: {e}\")\n",
        "                continue\n",
        "            \n",
        "            for _, row in df.iterrows():                \n",
        "                raw_file_name = str(row['file_name']).strip().split()[0]\n",
        "                video_path = os.path.join(root_dir, cls, raw_file_name)\n",
        "\n",
        "                # 파일이 실제로 존재하는지 확인 후 메타데이터에 추가\n",
        "                if os.path.exists(video_path):\n",
        "                    # 'exclude'가 행 어디든 포함되어 있다면 학습에서 제외\n",
        "                    # if 'exclude' in \" \".join(row.astype(str)).lower():\n",
        "                    #     continue\n",
        "\n",
        "                    self.clip_metadata.append({\n",
        "                        'video_path': video_path,\n",
        "                        'start_time': time_to_seconds(row['start_time']),\n",
        "                        'end_time': time_to_seconds(row['end_time']),\n",
        "                        'label': self.class_to_idx[cls]\n",
        "                    })\n",
        "        print(f\"Dataset initialized with {len(self.clip_metadata)} valid clips.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.clip_metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.clip_metadata[idx]\n",
        "        video = EncodedVideo.from_path(item['video_path'])\n",
        "        \n",
        "        # 지정된 start~end 구간의 비디오 데이터 로드\n",
        "        # 사고 구간이 너무 짧으면 모델 입력(2초 가량)에 맞춰 여백을 두거나 조절.\n",
        "        video_data = video.get_clip(start_sec=item['start_time'], end_sec=item['end_time'])\n",
        "        \n",
        "        video_tensor = video_data['video'] # (C, T, H, W)\n",
        "        \n",
        "        if self.transform:\n",
        "            # PyTorchVideo transform은 딕셔너리 형태 입력으로\n",
        "            video_data = self.transform(video_data)\n",
        "            \n",
        "        return video_data['video'], item['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e41bf70",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset initialized with 904 valid clips.\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 데이터셋 및 로더 선언\n",
        "train_dataset = UCFCrimeDataset(\n",
        "    root_dir=\"/mnt/c/JJS/UCF_Crimes/Videos/train\", \n",
        "    annotation_dir=\"/mnt/c/JJS/UCF_Crimes/Videos/train/00_timestamp\",\n",
        "    transform=transform # 앞서 정의한 비디오 입력 전처리 transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "Bumr3HIfEDZj",
      "metadata": {
        "id": "Bumr3HIfEDZj"
      },
      "outputs": [],
      "source": [
        "# 학습 함수 정의\n",
        "def train_one_epoch(model, data_loader, criterion, optimizer, device):\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  for inputs, labels in data_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  return total_loss / len(data_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vdefvCusF7Rb",
      "metadata": {
        "id": "vdefvCusF7Rb"
      },
      "source": [
        "#### Start Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2qgT7jUE-ejL",
      "metadata": {
        "id": "2qgT7jUE-ejL"
      },
      "source": [
        "##### 손실함수 및 옵티마이저\n",
        "\n",
        "- 차등 학습률 (Differential Learning Rate)\n",
        "\n",
        "  > UCF-CRIME 다중 클래스 분류를 위한 Cross Entropy Loss 사용 <br>이때 교체한 출력헤드에 대해서만 10배 가량 큰 학습률 설정 <br>(완전 램덤 상태에서 출발하기 때문, 학술적으로 권장되는 전이 학습 전략)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RQpzNJFpBV86",
      "metadata": {
        "id": "RQpzNJFpBV86"
      },
      "source": [
        "##### 사전학습 가중치 동결\n",
        "\n",
        "- **Phase 1:** Backbone(blocks[0:5])을 동결하고 새로 만든 Head만 2~3 Epoch 정도 학습. <br>(무작위 가중치가 사전 학습된 Backbone을 망치는 것을 방지)\n",
        "- **Phase 2:** 모든 레이어 동결을 해제하고 전체 네트워크를 파인튠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "OzaAi5etF2nT",
      "metadata": {
        "id": "OzaAi5etF2nT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected device: cuda\n",
            "Starting Phase 1: Training Head Only...\n",
            "Phase 1 - Epoch 0: Loss 2.3086\n",
            "Phase 1 - Epoch 1: Loss 1.8961\n",
            "Starting Phase 2: Full Fine-tuning...\n",
            "Phase 2 - Epoch 1, Loss: 1.7317\n",
            "Phase 2 - Epoch 2, Loss: 1.6097\n",
            "Phase 2 - Epoch 3, Loss: 1.5215\n",
            "Phase 2 - Epoch 4, Loss: 1.4336\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "DataLoader worker (pid(s) 141257) exited unexpectedly",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1285\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1284\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py12/lib/python3.12/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    112\u001b[39m timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py12/lib/python3.12/multiprocessing/connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py12/lib/python3.12/multiprocessing/connection.py:440\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     r = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py12/lib/python3.12/multiprocessing/connection.py:1136\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py12/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py12/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[39m, in \u001b[36m_set_SIGCHLD_handler.<locals>.handler\u001b[39m\u001b[34m(signum, frame)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhandler\u001b[39m(signum, frame):\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid 141257) is killed by signal: Killed. ",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     28\u001b[39m optimizer_p2 = optim.SGD([\n\u001b[32m     29\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m'\u001b[39m: model.blocks[:\u001b[32m5\u001b[39m].parameters(), \u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m1e-5\u001b[39m},\n\u001b[32m     30\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m'\u001b[39m: model.blocks[\u001b[32m5\u001b[39m].proj.parameters(), \u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m1e-3\u001b[39m} \u001b[38;5;66;03m# 빠른 수렴 유발\u001b[39;00m\n\u001b[32m     31\u001b[39m ], momentum=\u001b[32m0.9\u001b[39m, weight_decay=\u001b[32m1e-4\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m   loss = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_p2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPhase 2 - Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, data_loader, criterion, optimizer, device)\u001b[39m\n\u001b[32m      3\u001b[39m model.train()\n\u001b[32m      4\u001b[39m total_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m  \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m  \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1492\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1491\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1492\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1495\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1454\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1451\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1452\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1453\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1454\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1455\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1456\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1298\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1297\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1299\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1300\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 141257) exited unexpectedly"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Selected device: {device}\")\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# phase 1\n",
        "print(\"\\nStarting Phase 1: Training Head Only...\")\n",
        "\n",
        "for param in model.blocks[:5].parameters():\n",
        "  param.requires_grad = False\n",
        "for param in model.blocks[5].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "optimizer_p1 = optim.SGD(model.blocks[5].parameters(), lr=1e-3, momentum=0.9)\n",
        "for epoch in range(2):\n",
        "  train_loss = train_one_epoch(model, train_loader, criterion, optimizer_p1, device)\n",
        "  print(f\"Phase 1 - Epoch {epoch}: Loss {train_loss:.4f}\")\n",
        "\n",
        "# phase 2\n",
        "print(\"\\nStarting Phase 2: Full Fine-tuning...\")\n",
        "for param in model.parameters(): # 전체 레이어 trainable\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Head와 backbone의 학습률을 서로 다르게 적용하기 위해 분리\n",
        "optimizer_p2 = optim.SGD([\n",
        "    {'params': model.blocks[:5].parameters(), 'lr':1e-5},\n",
        "    {'params': model.blocks[5].proj.parameters(), 'lr':1e-3} # 빠른 수렴 유발\n",
        "], momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(5):\n",
        "  loss = train_one_epoch(model, train_loader, criterion, optimizer_p2, device)\n",
        "  print(f\"Phase 2 - Epoch {epoch+1}, Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "43jKmbzFIkOv",
      "metadata": {
        "id": "43jKmbzFIkOv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Abuse': 0,\n",
              " 'Arrest': 1,\n",
              " 'Arson': 2,\n",
              " 'Assault': 3,\n",
              " 'Burglary': 4,\n",
              " 'Explosion': 5,\n",
              " 'Fighting': 6,\n",
              " 'Normal': 7,\n",
              " 'RoadAccidents': 8,\n",
              " 'Robbery': 9,\n",
              " 'Shooting': 10,\n",
              " 'Shoplifting': 11,\n",
              " 'Stealing': 12,\n",
              " 'Vandalism': 13}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.class_to_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ecb5434",
      "metadata": {
        "id": "9ecb5434"
      },
      "source": [
        "#### Run Inference\n",
        "\n",
        "Download an example video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7a22cf8",
      "metadata": {
        "id": "d7a22cf8"
      },
      "outputs": [],
      "source": [
        "url_link = \"https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4\"\n",
        "video_path = 'archery.mp4'\n",
        "\n",
        "try: urllib.URLopener().retrieve(url_link, video_path)\n",
        "except: urllib.request.urlretrieve(url_link, video_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f456ad9e",
      "metadata": {
        "id": "f456ad9e"
      },
      "source": [
        "Load the video and transform it to the input format required by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a17edf8",
      "metadata": {
        "id": "3a17edf8"
      },
      "outputs": [],
      "source": [
        "# Select the duration of the clip to load by specifying the start and end duration\n",
        "# The start_sec should correspond to where the action occurs in the video\n",
        "start_sec = 0\n",
        "end_sec = start_sec + clip_duration\n",
        "\n",
        "# Initialize an EncodedVideo helper class and load the video\n",
        "video = EncodedVideo.from_path(video_path) # pytorchvideo.data.encoded_video.EncodedVideo\n",
        "\n",
        "# Load the desired clip\n",
        "video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
        "\n",
        "# Apply a transform to normalize the video input\n",
        "video_data = transform(video_data)\n",
        "\n",
        "# Move the inputs to the desired device\n",
        "inputs = video_data[\"video\"]\n",
        "inputs = inputs.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3VV7fhb56DRd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VV7fhb56DRd",
        "outputId": "11038794-77f3-4507-e57f-5abf8236c898"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pytorchvideo.data.encoded_video_pyav.EncodedVideoPyAV at 0x7a16e0454c20>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "video"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7910399",
      "metadata": {
        "id": "e7910399"
      },
      "source": [
        "#### Get Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7uQy5Sds8Jwp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uQy5Sds8Jwp",
        "outputId": "993633f5-33e0-4654-9882-11f597301884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 13, 182, 182])\n",
            "torch.Size([1, 3, 13, 182, 182])\n"
          ]
        }
      ],
      "source": [
        "print(inputs.size()) # c, t, h, W\n",
        "print(inputs[None, ...].size()) # 1, C, T, H, W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1529bab5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1529bab5",
        "outputId": "01059745-aa8b-4d3e-cb7d-1115acaa30fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 predicted labels: archery, throwing axe, golf driving, golf chipping, opening bottle\n"
          ]
        }
      ],
      "source": [
        "# Pass the input clip through the model\n",
        "preds = model(inputs[None, ...])\n",
        "\n",
        "# Get the predicted classes\n",
        "# 로짓 값을 클래스명으로 매핑시키기 위한 후처리.\n",
        "post_act = torch.nn.Softmax(dim=1)\n",
        "preds = post_act(preds)\n",
        "pred_classes = preds.topk(k=5).indices[0]\n",
        "\n",
        "# Map the predicted classes to the label names\n",
        "pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_classes]\n",
        "print(\"Top 5 predicted labels: %s\" % \", \".join(pred_class_names)) # 양궁, 도끼 던지기, 골프 높게 치는 샷, 골프 낮게 치는 샷, 보틀 열기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UGxGmV2c6zWw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGxGmV2c6zWw",
        "outputId": "7aeeab97-1adc-4161-93c7-a6c9cb2a527a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 400])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds.size() # 400 = Kinetics 데이터셋의 클래스 개수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3a6d61",
      "metadata": {
        "id": "9b3a6d61"
      },
      "source": [
        "### Model Description\n",
        "X3D model architectures are based on [1] pretrained on the Kinetics dataset.\n",
        "\n",
        "| arch | depth | frame length x sample rate | top 1 | top 5 | Flops (G) | Params (M) |\n",
        "| --------------- | ----------- | ----------- | ----------- | ----------- | ----------- |  ----------- | ----------- |\n",
        "| X3D      | XS    | 4x12                       | 69.12 | 88.63 | 0.91      | 3.79     |\n",
        "| X3D      | S     | 13x6                       | 73.33 | 91.27 | 2.96      | 3.79     |\n",
        "| X3D      | M     | 16x5                       | 75.94 | 92.72 | 6.72      | 3.79     |\n",
        "\n",
        "\n",
        "### References\n",
        "[1] Christoph Feichtenhofer, \"X3D: Expanding Architectures for\n",
        "    Efficient Video Recognition.\" https://arxiv.org/abs/2004.04730"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bY_sVaYX_0pA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY_sVaYX_0pA",
        "outputId": "c8d3676b-56c9-4272-e231-5f846df7fe73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch                                    2.9.0+cpu\n",
            "torchao                                  0.10.0\n",
            "torchaudio                               2.9.0+cpu\n",
            "torchdata                                0.11.0\n",
            "torchsummary                             1.5.1\n",
            "torchtune                                0.6.1\n",
            "torchvision                              0.24.0+cpu\n"
          ]
        }
      ],
      "source": [
        "!pip list |grep torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bkc8gTA8_12y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkc8gTA8_12y",
        "outputId": "b8c33b7a-283a-4589-97f3-8d63fbd911cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fvcore                                   0.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip list |grep fvcore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mM3OFvktDroI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM3OFvktDroI",
        "outputId": "13d8a324-afef-40ec-93ac-7a054644a442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gcc (Ubuntu 11.4.0-1ubuntu1~22.04.2) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pfH-t1k8DsoA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfH-t1k8DsoA",
        "outputId": "41538aaf-fafb-4f7a-ca20-c1187f55dc33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.12.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "amgK7JmID5II",
      "metadata": {
        "id": "amgK7JmID5II"
      },
      "outputs": [],
      "source": [
        "!pip list |grep pytorchvideo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wai3gA_kExi_",
      "metadata": {
        "id": "wai3gA_kExi_"
      },
      "source": [
        "## Directly Inference on UCF-CRIME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tPmgl2GMEZJQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPmgl2GMEZJQ",
        "outputId": "2b4666e0-4a6f-46dd-ba35-e928c1ba983a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clip duration: 2.6 (sec)\n",
            "Top 5 predicted labels: moving furniture, cleaning floor, hoverboarding, using remote controller (not gaming), garbage collecting\n"
          ]
        }
      ],
      "source": [
        "print(f\"clip duration: {clip_duration} (sec)\")\n",
        "\n",
        "# Select the duration of the clip to load by specifying the start and end duration\n",
        "# The start_sec should correspond to where the action occurs in the video\n",
        "start_sec = 0\n",
        "end_sec = start_sec + clip_duration\n",
        "\n",
        "# Initialize an EncodedVideo helper class and load the video\n",
        "ucf_video_path=\"/content/Abuse001_x264_7-12.mp4\"\n",
        "ucf_video = EncodedVideo.from_path(ucf_video_path) # pytorchvideo.data.encoded_video.EncodedVideo\n",
        "\n",
        "# Load the desired clip\n",
        "ucf_video_data = ucf_video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
        "\n",
        "# Apply a transform to normalize the video input\n",
        "ucf_video_transformed = transform(ucf_video_data)\n",
        "ucf_inputs = ucf_video_transformed[\"video\"] # 인코딩된 비디오 텐서값만\n",
        "ucf_inputs = ucf_inputs.to(device)\n",
        "\n",
        "ucf_preds = model(ucf_inputs[None, ...]) # 배치차원 추가하여 (1, C, T, H, W)\n",
        "\n",
        "# Get the predicted classes\n",
        "post_act = torch.nn.Softmax(dim=1)\n",
        "ucf_pred_classes = post_act(ucf_preds)\n",
        "ucf_pred_top5 = ucf_pred_classes.topk(k=5).indices[0]\n",
        "\n",
        "# Map the predicted classes to the label names\n",
        "ucf_pred_top5_names = [kinetics_id_to_classname[int(i)] for i in ucf_pred_top5]\n",
        "print(\"Top 5 predicted labels: %s\" % \", \".join(ucf_pred_top5_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Owj39BVUFYyB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owj39BVUFYyB",
        "outputId": "218c9ab4-f98f-4dce-b3a5-3e9e01abac7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 Predictions:\n",
            "1: moving furniture     | Score: 15.94 (%)\n",
            "2: cleaning floor       | Score: 15.64 (%)\n",
            "3: hoverboarding        | Score: 10.06 (%)\n",
            "4: using remote controller (not gaming) | Score: 7.65 (%)\n",
            "5: garbage collecting   | Score: 6.81 (%)\n"
          ]
        }
      ],
      "source": [
        "ucf_video_path=\"/content/Abuse001_x264_7-12.mp4\"\n",
        "ucf_video = EncodedVideo.from_path(ucf_video_path) # pytorchvideo.data.encoded_video.EncodedVideo\n",
        "\n",
        "# Load the desired clip\n",
        "ucf_video_data = ucf_video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
        "\n",
        "# Apply a transform to normalize the video input\n",
        "ucf_video_transformed = transform(ucf_video_data)\n",
        "ucf_inputs = ucf_video_transformed[\"video\"] # 인코딩된 비디오 텐서값만\n",
        "ucf_inputs = ucf_inputs.to(device)\n",
        "\n",
        "ucf_preds = model(ucf_inputs[None, ...]) # 배치차원 추가하여 (1, C, T, H, W)\n",
        "ucf_pred_classes = post_act(ucf_preds)   # post_act = torch.nn.Softmax(dim=1)\n",
        "\n",
        "# 확률값(v)과 인덱스(i) 모두 가져오기.\n",
        "top5_probs, top5_indices = ucf_pred_classes.topk(k=5)\n",
        "\n",
        "# 텐서 형태를 출력을 위한 넘파이로 변환\n",
        "probs = top5_probs[0].detach().cpu().numpy()\n",
        "indices = top5_indices[0].detach().cpu().numpy()\n",
        "\n",
        "# 클래스 이름과 확률을 매핑해 출력.\n",
        "print(\"Top 5 Predictions:\")\n",
        "for i in range(5):\n",
        "    class_name = kinetics_id_to_classname[int(indices[i])]\n",
        "    score = probs[i] * 100  # 퍼센트(%) 단위로 변환\n",
        "    print(f\"{i+1}: {class_name:<20} | Score: {score:.2f} (%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9JljRyyGxzB",
      "metadata": {
        "id": "a9JljRyyGxzB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
